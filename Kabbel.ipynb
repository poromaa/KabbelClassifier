{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Käbbel importerare\n",
    "\n",
    "Denna funktion läser allt käbbel från regeringens hemsida och sparar ner skiten i en fil: kabbel.txt\n",
    "- datasize kan sättas till hur många sidor som ska hämtas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Läs in fil och skapa ordvektor\n",
    "\n",
    "Denna läser in orden från ovan skapade fil och bygger en data av den som vi använder som träningsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request, json, re\n",
    "import pprint as pp\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def file_to_json(filename):\n",
    "    with open(filename,encoding=\"utf-8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "        return data\n",
    "\n",
    "def kabbel_to_vec(jsondata):\n",
    "    speech = []\n",
    "    classes = []\n",
    "    person = []\n",
    "    words = []\n",
    "    for sample in jsondata:\n",
    "        cleaned = re.sub(r'[.|,]', '', sample[\"kabbel\"])\n",
    "        words += cleaned.lower().split()\n",
    "        speech.append(cleaned)\n",
    "        classes.append(sample[\"parti\"])\n",
    "        person.append(sample[\"talare\"])\n",
    "\n",
    "    #print(speech)\n",
    "    #data = tf.compat.as_str(speech).split()\n",
    "    return speech, classes, person\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Läs in olika delar och tilldela X och Y i vår modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exempel på ett sample ur datan: \n",
      "[\n",
      "    {\n",
      "        \"kabbel\": \"jag ska fatta mig kort.\",\n",
      "        \"parti\": \"SD\",\n",
      "        \"talare\": \"Paula Bieler (SD)\"\n",
      "    },\n",
      "    {\n",
      "        \"kabbel\": \"jag har redan redogjort f\\u00f6r huvudargumentationen bakom detta,\",\n",
      "        \"parti\": \"SD\",\n",
      "        \"talare\": \"Paula Bieler (SD)\"\n",
      "    }\n",
      "]\n",
      "Classes: ['SD', 'SD', 'SD']... \n",
      "\n",
      "Speech:['jag ska fatta mig kort', 'jag har redan redogjort för huvudargumentationen bakom detta', 'men för att sammanfatta kan vi konstatera att vi har en situation i dagsläget där endera av två olika scenarier har utspelat sig de senaste åren']...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jsondata = file_to_json(\"kabbel_big.txt\")\n",
    "print(\"Exempel på ett sample ur datan: \\n\"+json.dumps(jsondata[:2], indent=4))\n",
    "\n",
    "\n",
    "speech, classes, person = kabbel_to_vec(jsondata)\n",
    "\n",
    "print(\"Classes: {0}... \\n\\nSpeech:{1}...\".format(classes[:3], speech[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anpassning av träningsdata (sample=X) och klassificering (Y)\n",
    "\n",
    "Vi konverterar varje sample till en träningsvektor av längden `len(unika antal ord)` och värde `n` för antal förekomst per ord\n",
    "\n",
    "Vi konverterar varje klasificering till en vektor som beskriver klasserna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def samples_to_vocab(samples):\n",
    "    all_unique_words = list(set(' '.join(samples).split(' '))) \n",
    "    word_to_idx = {i:w for w,i in enumerate(all_unique_words)}\n",
    "    idx_to_word = {i:w for i,w in enumerate(all_unique_words)}\n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "def sample_to_vec(sample, wi):\n",
    "    vocabular = wi\n",
    "    sample_words = np.array(sample.split(\" \"))\n",
    "    vec = np.array([wi[x] for x in sample_words])\n",
    "    one_hot = np.zeros([len(vec), len(vocabular)])\n",
    "    one_hot[np.arange(len(vec)),vec] = 1\n",
    "    one_hot = np.sum(one_hot,axis=0)\n",
    "    return vec,one_hot\n",
    "\n",
    "def samples_to_train(samples):\n",
    "    vocabulary, iw = samples_to_vocab(samples)\n",
    "    sample_vector = []\n",
    "    for sample in samples:\n",
    "        _, x = sample_to_vec(sample, vocabulary)\n",
    "        sample_vector.append(x)\n",
    "    return np.matrix(sample_vector).reshape((len(samples),len(vocabulary))).T, vocabulary, iw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jag ska fatta mig kort', 'jag har redan redogjort för huvudargumentationen bakom detta']\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(matrix([[ 0.,  1.],\n",
       "         [ 1.,  0.]]), {'Björn': 0, 'Joakim': 1}, {0: 'Björn', 1: 'Joakim'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data =[\n",
    "    {\n",
    "        \"talare\": \"Joakim\",\n",
    "        \"parti\": \"S\",\n",
    "        \"kabbel\": \"jag ska, fatta mig kort.\"\n",
    "    },\n",
    "    {\n",
    "        \"talare\": \"Björn\",\n",
    "        \"parti\": \"SD\",\n",
    "        \"kabbel\": \"jag har redan redogjort f\\u00f6r huvudargumentationen bakom detta,\"\n",
    "    }\n",
    "]\n",
    "\n",
    "test_samples,test_parti, test_classes = kabbel_to_vec(test_data)\n",
    "\n",
    "#test_samples = [\"Apan är Bäst\", \"Joakim är Bäst i klassen i alla fall\",\"Joakim\"]\n",
    "#test_classes = [\"Apan\", \"Joakim\",\"Joadkim\"]\n",
    "\n",
    "print(test_samples)\n",
    "a, b, c = samples_to_train(test_samples)\n",
    "print(a)\n",
    "samples_to_train(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_data_info(speech,classes,test_index=0):\n",
    "    X_train,vocabulary_x, _ = samples_to_train(speech)\n",
    "    Y_train,vocabulary_y, _ = samples_to_train(classes)\n",
    "    print(\"Antal unika ord (features X):\\t\",X_train.shape[0])\n",
    "    print(\"training samples m:\\t\\t\",Y_train.shape[1])\n",
    "    print(\"unika klassificeringar (Y):\\t\",Y_train.shape[0])\n",
    "    vec, one = sample_to_vec(speech[test_index],vocabulary_x)\n",
    "    print(\"X:\")\n",
    "    print(\"Original: {0}{1}\".format(speech[test_index][:70],\"...\" if len(speech[test_index])>70 else \"\"))\n",
    "    print(\"Vokabulär: {0}\".format([x for x in vocabulary_x][:10]))\n",
    "    print(\"x0 :\\n{0}\".format(vec))\n",
    "    print(\"x0 compressed:\\n{0}\\n\".format(X_train)) \n",
    "    print(\"Y:\")\n",
    "    print([x for x in vocabulary_y])\n",
    "    print(\"y0 compressed:\\n{0}\".format(Y_train)) \n",
    "    assert X_train.shape[1] == Y_train.shape[1] , 'Det måste finnas lika många X som Y:n'\n",
    "\n",
    "def print_shape_info(X_train,Y_train):\n",
    "    print(\"number of training examples: {0}\".format(X_train.shape[1]))\n",
    "    print(\"X_train shape: {0}\".format(str(X_train.shape)))\n",
    "    print(\"Y_train shape: {0}\".format(str(Y_train.shape)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: 5\n",
      "X_train shape: (9, 5)\n",
      "Y_train shape: (4, 5)\n",
      "Antal unika ord (features X):\t 9\n",
      "training samples m:\t\t 5\n",
      "unika klassificeringar (Y):\t 4\n",
      "X:\n",
      "Original: Apan är Bäst Bäst Bäst\n",
      "Vokabulär: ['i', 'Bäst', 'alla', 'Hejhej', 'är', 'Apan', 'fall', 'Joakim', 'klassen']\n",
      "x0 :\n",
      "[5 4 1 1 1]\n",
      "x0 compressed:\n",
      "[[ 0.  2.  0.  0.  0.]\n",
      " [ 3.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.]]\n",
      "\n",
      "Y:\n",
      "['Joadkim', 'Joakim', 'Annan', 'Apan']\n",
      "y0 compressed:\n",
      "[[ 0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\"Apan är Bäst Bäst Bäst\", \"Joakim är Bäst i klassen i alla fall\",\"Joakim\",\"Hejhej\",\"Joakim\"]\n",
    "test_classes = [\"Apan\", \"Joakim\",\"Joadkim\",\"Annan\",\"Joakim\"]\n",
    "\n",
    "\n",
    "\n",
    "X_samp,vocabulary_x, iw = samples_to_train(test_samples)\n",
    "Y_samp,vocabulary_y ,iw= samples_to_train(test_classes)\n",
    "\n",
    "print_shape_info(X_samp, Y_samp)\n",
    "print_data_info(test_samples,test_classes,test_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stop_words(X, iw, top=10):\n",
    "\n",
    "    X_samp_sum = np.sum(X,axis=1)\n",
    "    \n",
    "    idx = np.argsort(-X_samp_sum, axis=0)\n",
    "    iw_ar = [w for (i,w) in iw.items()]\n",
    "    count = X_samp_sum[idx[:top]].flatten()\n",
    "    labels = np.asarray(iw_ar)[idx[:top]]\n",
    "    a = count.tolist()[0]\n",
    "    b = labels.flatten().tolist()\n",
    "    z = dict(zip(b,a))\n",
    "    res = []\n",
    "    for k,v in z.items():\n",
    "        res.append(\"{0}\\t{1:20}\\t[{2}]\".format(len(res)+1,k,v).expandtabs(2))\n",
    "    print(\"\\n\".join(res))\n",
    "    return idx\n",
    "\n",
    "def remove_features(X_samp, del_idx, iw, remove):\n",
    "    #del_idx = get_stop_words(X_samp,iw,remove)\n",
    "    iwr = [w for (i,w) in iw.items()]\n",
    "    iwr = np.delete(iwr, del_idx[:remove], axis=0)\n",
    "    X_red = np.delete(X_samp, del_idx[:remove], axis=0)\n",
    "    \n",
    "    assert X_samp.shape[0] == X_red.shape[0]+remove\n",
    "    return X_red, iwr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Bäst                  [4.0]\n",
      "2 Joakim                [3.0]\n",
      "['i' 'alla' 'Hejhej' 'är' 'Apan' 'fall' 'klassen']\n"
     ]
    }
   ],
   "source": [
    "remove = 2\n",
    "\n",
    "X_samp,_, iw = samples_to_train(test_samples)\n",
    "del_idx = get_stop_words(X_samp,iw,remove)\n",
    "X_red, iwr = remove_features(X_samp,del_idx, iw, remove)\n",
    "\n",
    "print(iwr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(X,Y, seed=1):\n",
    "    np.random.seed(1)\n",
    "    randomize = np.arange(X.shape[1])\n",
    "    np.random.shuffle(randomize)\n",
    "    #blanda kolumnerna\n",
    "    X = X[:,randomize]\n",
    "    Y = Y[:,randomize]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0.4359949 ,  0.02592623,  0.54966248,  0.43532239,  0.4203678 ],\n",
      "       [ 0.33033482,  0.20464863,  0.61927097,  0.29965467,  0.26682728]])\n",
      "array([[ 0.54966248,  0.02592623,  0.4203678 ,  0.4359949 ,  0.43532239],\n",
      "       [ 0.61927097,  0.20464863,  0.26682728,  0.33033482,  0.29965467]])\n",
      "array([[ 0.54966248,  0.02592623,  0.4203678 ,  0.4359949 ,  0.43532239],\n",
      "       [ 0.61927097,  0.20464863,  0.26682728,  0.33033482,  0.29965467]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "a = np.random.rand(2,5)\n",
    "b,c  = shuffle(a,a,1)\n",
    "pp.pprint(a)\n",
    "pp.pprint(b)\n",
    "pp.pprint(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_dev_test(X,Y,ratio=.5):\n",
    "    np.random.seed(2)\n",
    "    m = X.shape[1]\n",
    "    m_train = int(np.floor((X.shape[1]*ratio)))\n",
    "    m_bi = int((m - m_train)/2)\n",
    "    \n",
    "    X_orig, Y_orig = shuffle(X,Y)\n",
    "    \n",
    "    X_train, X_dev, X_test = X_orig[:,:m_train], X_orig[:,m_train:m_train+m_bi], X_orig[:,m_train+m_bi:]\n",
    "    Y_train, Y_dev, Y_test = Y_orig[:,:m_train], Y_orig[:,m_train:m_train+m_bi], Y_orig[:,m_train+m_bi:]\n",
    "    print(m_train,m_bi+m_train)\n",
    "    return X_train, X_dev, X_test, Y_train, Y_dev, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "m:5\n",
      "m_train:4\n",
      "m_dev:0\n",
      "m_test:1\n",
      "[[ 0.  2.  0.  0.  0.]\n",
      " [ 3.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.]]\n",
      "(9, 4)\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print_data_info(speech,classes)\n",
    "x_train,vocabulary_x,_ = samples_to_train(test_samples)\n",
    "y_train,vocabulary_y,_ = samples_to_train(test_classes)\n",
    "X_train, X_dev, X_test, Y_train, Y_dev, Y_test = split_train_dev_test(x_train,y_train,ratio=.9)\n",
    "m = x_train.shape[1]\n",
    "print('m:{0}'.format(m))\n",
    "print('m_train:{0}'.format(X_train.shape[1]))\n",
    "print('m_dev:{0}'.format(X_dev.shape[1]))\n",
    "print('m_test:{0}'.format(X_test.shape[1]))\n",
    "\n",
    "print(x_train)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "assert m == Y_train.shape[1]+Y_dev.shape[1] + Y_test.shape[1]\n",
    "assert m == X_train.shape[1]+X_dev.shape[1] +X_test.shape[1] #\"matrisen harinte samma features\"\n",
    "assert X_train.shape[0] == X_dev.shape[0] #matrisen behåller formen features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x,n_y):\n",
    "    X = tf.placeholder(shape=[n_x,None],dtype=tf.float32,name=\"X\")\n",
    "    Y = tf.placeholder(shape=[n_y,None],dtype=tf.float32,name=\"Y\")\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiera parametrar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_params(hyperparameters):\n",
    "    \"\"\"Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\"\"\"\n",
    "    \n",
    "    layer_dims = hyperparameters['layer_dims']\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = tf.get_variable(name=\"W\"+str(l),shape=[layer_dims[l],layer_dims[l-1]],initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "        parameters['b' + str(l)] = tf.get_variable(name=\"b\"+str(l),shape=[layer_dims[l],1],initializer=tf.zeros_initializer())\n",
    "\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_hyperparams(layer_dims):\n",
    "    hyperparameters = {}\n",
    "    hyperparameters['layer_dims'] = layer_dims\n",
    "    \n",
    "    return hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': <tf.Variable 'W1:0' shape=(25, 9) dtype=float32_ref>,\n",
      " 'W2': <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>,\n",
      " 'W3': <tf.Variable 'W3:0' shape=(4, 12) dtype=float32_ref>,\n",
      " 'b1': <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>,\n",
      " 'b2': <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>,\n",
      " 'b3': <tf.Variable 'b3:0' shape=(4, 1) dtype=float32_ref>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph() #nollställ modell\n",
    "hyperparameters = init_hyperparams(layer_dims=[X_train.shape[0],25,12,Y_train.shape[0]])\n",
    "paramteters = initialize_params(hyperparameters)\n",
    "\n",
    "pp.pprint(paramteters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, hyperparameters, parameters):\n",
    "    layer_dims = hyperparameters['layer_dims']\n",
    "    L = len(layer_dims)-1\n",
    "  \n",
    "    Zi = {}\n",
    "    Ai = {}\n",
    "    Ai[0] = X\n",
    "    for l in range(1,L+1):\n",
    "        Zi[l] = tf.matmul(parameters['W'+str(l)],Ai[l-1])+parameters['b'+str(l)]\n",
    "        Ai[l] = tf.nn.relu(Zi[l])\n",
    "        #print(\"ff\"+str(l)+\" \"+'W'+str(l)+\"x\"+\"Ai[\"+str(l-1)+\"] + \"+'b'+str(l))\n",
    "\n",
    "    return Zi[L]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a24c00bfd603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mZ3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(X_train.shape[0], Y_train.shape[0])\n",
    "    parameters = initialize_params(hyperparameters)\n",
    "    Z3 = forward_propagation(X, hyperparameters, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(X_train.shape[0], Y_train.shape[0])\n",
    "    parameters = initialize_params(hyperparameters)\n",
    "    Z3 = forward_propagation(X, hyperparameters, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kostnadsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \n",
    "    #    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    #biases = tf.Variable(tf.zeros([num_labels]))\n",
    "   # weights = tf.Variable(tf.truncated_normal([Z3.shape[0], Z3.shape[1]]))\n",
    "   # biases = tf.Variable(tf.zeros([Z3.shape[1]]))\n",
    "  \n",
    "    # Training computation.\n",
    "   # logits = tf.transpose(tf.matmul(Z3, weights) + biases )\n",
    "    logits = tf.transpose(Z3 + Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    # L2_regularization_cost = lambd/(2*m)*(np.sum(np.square(W1))+np.sum(np.square(W2))+np.sum(np.square(W3)))\n",
    "    #kostnadsfunktion ej regulariserad.\n",
    "    #logits = tf.matmul(tf_train_dataset, weights) + biases \n",
    "    # Original loss function\n",
    "    #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    \n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost_with_regularization(Z3, Y, parameters, lambd):\n",
    "\n",
    "    layer_dims = hyperparameters['layer_dims']\n",
    "    L = len(layer_dims)-1\n",
    "    L2_regularization_cost = tf.Variable(0,dtype=tf.float32)\n",
    "    for l in range(1,L):\n",
    "        L2_regularization_cost +=  tf.nn.l2_loss(parameters['W'+str(l)]) \n",
    "\n",
    "\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels)\n",
    "    \n",
    "    cost = tf.reduce_mean(loss + lambd*L2_regularization_cost)\n",
    "\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = hyperparameters['layer_dims']\n",
    "L = len(layer_dims)-1\n",
    "for l in range(1,L):\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X_train,vocabulary_x, iw = samples_to_train(test_samples)\n",
    "Y_train,vocabulary_y ,iw= samples_to_train(test_classes)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y, mb = create_placeholders(X_train.shape[0], Y_train.shape[0])\n",
    "    parameters = initialize_params(hyperparameters)\n",
    "    Z3 = forward_propagation(X, hyperparameters, parameters)\n",
    "    cost = compute_cost_with_regularization(Z3, Y,parameters,.1,mb)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X_train, Y_train, minibatch_size, seed):\n",
    "    \"\"\"Tar in hela train och delar upp i x antal minibatch_size\n",
    "        med randomiserade kolumner (träningsexempel)\"\"\"\n",
    "    cuts = int(X_train.shape[1] / minibatch_size)\n",
    "    X_train, Y_train = shuffle(X_train, Y_train, seed)\n",
    "    minibatch_X = []\n",
    "    minibatch_Y = []\n",
    "    minibatches = []\n",
    "\n",
    "    for i in range(0,cuts+1):\n",
    "        minibatches.append((X_train[:,i*minibatch_size:(i+1)*minibatch_size],Y_train[:,i*minibatch_size:(i+1)*minibatch_size]))\n",
    "\n",
    "    return minibatches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.floor(np.random.rand(3,11)*10)\n",
    "minibatches = random_mini_batches(a,a,3,1)\n",
    "\n",
    "print(a)\n",
    "for (_,b) in minibatches:\n",
    "    pp.pprint(b)\n",
    "\n",
    "print(\"\\nbatch lengths: {0}\".format([b.shape[1] for (_,b) in minibatches]))\n",
    "print(sum([b.shape[1] for (_,b) in minibatches]))\n",
    "assert sum([b.shape[1] for (_,b) in minibatches]) == a.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell\n",
    "Här börjar vi om fast använder ovan funktioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 most used words:\n",
      "1 att                   [1667.0]\n",
      "2 det                   [1271.0]\n",
      "3 och                   [1058.0]\n",
      "4 i                     [947.0]\n",
      "5 är                    [839.0]\n",
      "6 som                   [837.0]\n",
      "7 har                   [633.0]\n",
      "8 för                   [612.0]\n",
      "9 vi                    [565.0]\n",
      "10  en                    [528.0]\n",
      "11  jag                   [480.0]\n",
      "12  på                    [404.0]\n",
      "13  till                  [401.0]\n",
      "14  inte                  [389.0]\n",
      "15  av                    [381.0]\n",
      "16  de                    [376.0]\n",
      "17  om                    [373.0]\n",
      "18  den                   [354.0]\n",
      "19  med                   [347.0]\n",
      "20  man                   [305.0]\n",
      "21  ett                   [297.0]\n",
      "22  kan                   [214.0]\n",
      "23  ska                   [209.0]\n",
      "24  också                 [192.0]\n",
      "25  när                   [167.0]\n",
      "26  här                   [163.0]\n",
      "27  detta                 [160.0]\n",
      "28  regeringen            [155.0]\n",
      "29  men                   [141.0]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "['finansmarknadsministern:' 'medlemsstatsstyrd' 'benämningen' ...,\n",
      " 'säkrare' 'påminde' 'räcker']\n",
      "2217 2494\n",
      "{'KD': 0, 'S': 1, 'SD': 2, 'MP': 3, 'M': 4}\n",
      "train:(5165, 2217) dev:(5165, 277) test:(5165, 278)\n"
     ]
    }
   ],
   "source": [
    "jsondata = file_to_json(\"kabbel.txt\")\n",
    "speech, classes, person = kabbel_to_vec(jsondata)\n",
    "\n",
    "X_orig,vocabulary_x,iwx = samples_to_train(speech)\n",
    "Y_orig,vocabulary_y,iwy = samples_to_train(classes)\n",
    "\n",
    "#REMOVE STOP WORDS\n",
    "remove = 29\n",
    "print(\"{0} most used words:\".format(remove))\n",
    "del_idx = get_stop_words(X_orig,iwx,remove)\n",
    "X_orig, iwx_red = remove_features(X_orig,del_idx,iwx,remove)\n",
    "\n",
    "print(X_orig)\n",
    "row_sums = np.sum(X_orig,axis=1)\n",
    "print(iwx_red)\n",
    "#NORMALIZE X // not used\n",
    "#X_orig = X_orig / row_sums\n",
    "#print(X_orig)\n",
    "\n",
    "X_train, X_dev, X_test, Y_train, Y_dev, Y_test = split_train_dev_test(X_orig,Y_orig,ratio=.80)\n",
    "#print_data_info(speech,classes,test_index=0)\n",
    "\n",
    "print(vocabulary_y)\n",
    "print(\"train:{0} dev:{1} test:{2}\".format(X_train.shape,X_dev.shape,X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#epoch = antal iterationer över samma samples fast med olika rand. dist. (som montecarlo eller nått)\n",
    "\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.1,\n",
    "          num_epochs = 3000, minibatch_size = 512, print_cost = True, lambd = 0.9):\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results  \n",
    "    seed = 1                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "\n",
    "    \n",
    "    #skapa tomma placeholders för vår data\n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "    CLR_learning_rate = tf.Variable(learning_rate,tf.float32)\n",
    "    \n",
    "    #skapa hyperparameter om lager och units samt aktiveringsfunktioner per lager ()\n",
    "    hyperparameters = init_hyperparams(layer_dims=[X_train.shape[0],10,5,Y_train.shape[0]])\n",
    "    #skapa W b i varje lager\n",
    "    parameters = initialize_params(hyperparameters)\n",
    "\n",
    "    #initiera beräkningsgrafen för forward/backward prop\n",
    "    Z3 = forward_propagation(X,hyperparameters,parameters)\n",
    "\n",
    "    #initiera beräkningsgraf för kostnaden \n",
    "    cost = compute_cost_with_regularization(Z3, Y, parameters, lambd) #compute_cost(Z3,Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    #nu med learning rate decay\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=CLR_learning_rate, name='Adam').minimize(cost)\n",
    "   \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    epoch_print = 100\n",
    "    e_count = 0\n",
    "    tr_acc =[]\n",
    "    t_acc=[]\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        model_start_time = time.time()\n",
    "        last_time = model_start_time\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed +=1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            cycl = len(minibatches)\n",
    "            minlr = 0.001\n",
    "            mbi = 0\n",
    "            for minibatch in minibatches:\n",
    "                mbi +=1\n",
    "                #lr = 0.001+(mbi*(maxlr-0.001)/cycl)\n",
    "                lr = 0.001+mbi*0.001\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, \n",
    "                                                                            Y: minibatch_Y,\n",
    "                                                                            CLR_learning_rate: lr})\n",
    "            \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and (epoch % epoch_print == 0 and epoch > 0) or epoch == 10:\n",
    "                \n",
    "                t_now = time.time()\n",
    "                e_count = epoch-e_count\n",
    "                e_time = (t_now-last_time)/e_count\n",
    "               \n",
    "                est_end = (num_epochs - epoch)*e_time + t_now\n",
    "                st = datetime.datetime.fromtimestamp(est_end).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                if epoch == 10:\n",
    "                    print(\"{0}\".format(datetime.timedelta(seconds=(est_end-t_now))))\n",
    "                print(\"Cost after epoch {0}: {1} - epoch time {2} - est end: {3}\".format(epoch, epoch_cost,e_time,st))\n",
    "                last_time = t_now\n",
    "                t_accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Z3), tf.argmax(Y)), \"float\"))\n",
    "                \n",
    "                tr_acc.append(t_accuracy.eval({X: X_train, Y: Y_train}))\n",
    "                t_acc.append(t_accuracy.eval({X: X_test, Y: Y_test}))\n",
    "                \n",
    "                plt.plot(np.squeeze(tr_acc))\n",
    "                plt.plot(np.squeeze(t_acc))\n",
    "                        \n",
    "                plt.show()\n",
    "                \n",
    "                \n",
    "            if print_cost == True and epoch % 10 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                if costs[0] < epoch_cost:\n",
    "                    print(\"SOMETHING IS WRONG - cost increase?!\")\n",
    "                    break\n",
    "                \n",
    "       \n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        print(hyperparameters)\n",
    "        \n",
    "         # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: 2217\n",
      "X_train shape: (5165, 2217)\n",
      "Y_train shape: (5, 2217)\n",
      "0:13:35.995625\n",
      "Cost after epoch 10: 2.6605343222618103 - epoch time 0.16352617740631104 - est end: 2017-09-25 23:19:15\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUmMgSJIA+H/YRZyW9sNLCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119147f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 100: -0.49303705990314484 - epoch time 0.14908453358544244 - est end: 2017-09-25 23:18:02\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQIMBElSYyBIkgADQZLUGAiSJAD+H9cqhJApamarAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fb425c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 200: -2.7431244254112244 - epoch time 0.1352613015608354 - est end: 2017-09-25 23:16:56\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fc1b208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 300: -4.993368744850159 - epoch time 0.07813232572455155 - est end: 2017-09-25 23:12:29\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118b7e320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 400: -7.2431042194366455 - epoch time 0.07037929580325172 - est end: 2017-09-25 23:12:00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fe01320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 500: -9.493188381195068 - epoch time 0.05086035892881196 - est end: 2017-09-25 23:10:40\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAkwECRJjYEgSQIMBElSYyBIkgD4f+GRBQSjWaAEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119336048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-8a98cb765c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint_shape_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-0b4abd7b8ca1>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost, lambd)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, \n\u001b[1;32m     69\u001b[0m                                                                             \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                                                             CLR_learning_rate: lr})\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mepoch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/y-/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/y-/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/y-/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/y-/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/y-/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print_shape_info(X_train, Y_train)\n",
    "parameters = model(X_train, Y_train, X_test, Y_test, learning_rate = 0.001, num_epochs = 5000,lambd = 0.9)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ran_vec(length,n_min,n_max,log=False):\n",
    "    vec = []\n",
    "    random.seed(2)\n",
    "    random.randint(1,1031)*10\n",
    "    np.random.randint(1, 13, size=length)\n",
    "    \n",
    "    for i in range(length):\n",
    "        vec[np.rand()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exponential() got an unexpected keyword argument 'base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-1d4849ecc502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlayer_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexponential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlrate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.exponential (numpy/random/mtrand/mtrand.c:21527)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: exponential() got an unexpected keyword argument 'base'"
     ]
    }
   ],
   "source": [
    "lrate = []\n",
    "for l in range(2,6):\n",
    "    layer_dims = np.random.randint(1, 13, size=l)\n",
    "    learning_rate = np.random.exponential(1)\n",
    "    lrate.append(learning_rate)\n",
    "    print(learning_rate)\n",
    "    \n",
    "#learning_rate .1 .01 .001 (10)\n",
    "#layers 2-6 (4)\n",
    "#units 2, 3, 4, 5 (4)\n",
    "#lambd .9\n",
    "\n",
    "plt.plot(lrate)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.03817021620466"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.exponential(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train Accuracy: 0.587367\n",
    "Test Accuracy: 0.282962\n",
    "{'layer_dims': [16506, 10, 5, 12]}\n",
    "\n",
    "number of training examples: 13283\n",
    "X_train shape: (16506, 13283)\n",
    "Y_train shape: (12, 13283)\n",
    "0:23:02.283483\n",
    "Cost after epoch 1: 2.547187099456787 - epoch time 6.946148157119751 - est end: 2017-09-21 17:02:05\n",
    "Cost after epoch 100: 0.399053031206131 - epoch time 3.540127908340608 - est end: 2017-09-21 16:50:47\n",
    "Parameters have been trained!\n",
    "Train Accuracy: 0.959723\n",
    "Test Accuracy: 0.268513\n",
    "{'layer_dims': [16506, 10, 5, 12]}\n",
    "\n",
    "Cost after epoch 0: 1.944496\n",
    "Cost after epoch 100: 0.072316\n",
    "Cost after epoch 200: 0.060759\n",
    "Parameters have been trained!\n",
    "Train Accuracy: 0.992783\n",
    "Test Accuracy: 0.503597\n",
    "{'layer_dims': [16506, 25, 12, 12]}\n",
    "--- 43.270642042160034 seconds ---\n",
    "\n",
    "number of training examples: 2217\n",
    "X_train shape: (5165, 2217)\n",
    "Y_train shape: (5, 2217)\n",
    "4\n",
    "ff1 W1xAi[0] + b1\n",
    "ff2 W2xAi[1] + b2\n",
    "ff3 W3xAi[2] + b3\n",
    "ff4 W4xAi[3] + b4\n",
    "Parameters have been trained!\n",
    "Train Accuracy: 0.983762\n",
    "Test Accuracy: 0.528777\n",
    "--- 143.9702799320221 seconds ---\n",
    "\n",
    "\n",
    "number of training examples: 2217\n",
    "X_train shape: (5165, 2217)\n",
    "Y_train shape: (5, 2217)\n",
    "4\n",
    "ff1 W1xAi[0] + b1\n",
    "ff2 W2xAi[1] + b2\n",
    "ff3 W3xAi[2] + b3\n",
    "ff4 W4xAi[3] + b4\n",
    "Cost after epoch 0: 2.557675\n",
    "Cost after epoch 20: 2.010333\n",
    "Cost after epoch 40: 1.836701\n",
    "Cost after epoch 60: 1.696013\n",
    "Cost after epoch 80: 1.532787\n",
    "\n",
    "Parameters have been trained!\n",
    "Train Accuracy: 0.820478\n",
    "Test Accuracy: 0.57554\n",
    "--- 14.365275144577026 seconds ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test av modellen på ny data\n",
    "en predict-funktion som kör modellens forward-pass och använder softmax för klassificering till någon av de giltiga Y-värdena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(speech, parameters, vocabulary):\n",
    "        sample_to_vec(speech, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X_samp):\n",
    "    init = tf.global_variables_initializer()\n",
    "    X = tf.placeholder(shape=[X_train.shape[0],None],dtype=tf.float32,name=\"X\")\n",
    "    pred = forward_propagation(X,hyperparameters,parameters)\n",
    "    classify = tf.nn.softmax(tf.transpose(pred))\n",
    "    session = tf.Session()\n",
    "    session.run(init)\n",
    "    b = session.run(classify, feed_dict={X: X_samp})\n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bild\n",
      "L\n",
      "S\n"
     ]
    }
   ],
   "source": [
    "#XS_train, XS_dev, XS_test, YS_train, YS_dev, YS_test = split_train_dev_test(speech,classes,ratio=.82)\n",
    "sample_i = 1222\n",
    "b = predict(X_test[:,sample_i])\n",
    "c = np.zeros(b.shape[1]).astype(int)\n",
    "\n",
    "c[np.argmax(b)] = 1\n",
    "print(speech[sample_i])\n",
    "print(iwy[np.argmax(b)])\n",
    "print(classes[(sample_i-3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samples_to(speech,classes,idx):\n",
    "    xvocabulary, iwx = samples_to_vocab(speech)\n",
    "    yvocabulary, iwy = samples_to_vocab(classes)\n",
    "    \n",
    "    _, x = sample_to_vec(speech[idx], xvocabulary)\n",
    "    _, y = sample_to_vec(classes[idx], yvocabulary)\n",
    "    return speech[idx],classes[idx],x.T,y, iwx,iwy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_vec(sentence,vocabular):\n",
    "    sample_words = np.array(sentence.split(\" \"))\n",
    "    vec = np.array([vocabular.get(x) for x in sample_words if vocabular.get(x) is not None])\n",
    "    one_hot = np.zeros([len(vec), len(vocabular)])\n",
    "    one_hot[np.arange(len(vec)),vec] = 1\n",
    "    one_hot = np.sum(one_hot,axis=0)\n",
    "    return one_hot, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_predict(sentence,full_vocabulary,classY):\n",
    "    str_s = sentence.lower()\n",
    "    jvoc = np.asarray([k for k,v in full_vocabulary.items()])\n",
    "    print(jvoc.shape)\n",
    "    jvoc, iwx_red = remove_features(jvoc,del_idx,iwx,remove)\n",
    "\n",
    "    jvoc = dict(zip(jvoc,range(len(jvoc))))\n",
    "    \n",
    "    xr,_ =sentence_to_vec(str_s,jvoc)\n",
    "    xr = xr.reshape(xr.shape[0],1)\n",
    "    pred = predict(xr)\n",
    "    c = np.zeros(pred.shape[1]).astype(int)\n",
    "    c[np.argmax(pred)] = 1\n",
    "    \n",
    "    print(\"{0}\\n{1} ---> {2}\\n\\n\\n{3}\\n\".format(str_s,x,pred,classY[np.argmax(pred)]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16506, 16604)\n",
      "(16535,)\n",
      "(16535,)\n",
      "solidaritet\n",
      "[ 0.  0.  0. ...,  0.  0.  0.] ---> [[  3.47265537e-04   6.30126847e-03   1.38636431e-04   1.40720919e-01\n",
      "    1.26187308e-02   6.43577993e-01   1.88591093e-01   3.96953110e-05\n",
      "    5.23801544e-04   2.20969305e-05   7.08431471e-03   3.41737104e-05]]\n",
      "\n",
      "\n",
      "S\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_orig.shape)\n",
    "str_s,str_c,x,y,iwx,iwy =    samples_to(speech,classes,1)\n",
    "sample_i = 2622\n",
    "\n",
    "jvoc = np.asarray([k for k,v in vocabulary_x.items()])\n",
    "print(jvoc.shape)\n",
    "jvoc, iwx_red = remove_features(jvoc,del_idx,iwx,remove)\n",
    "\n",
    "jvoc = dict(zip(jvoc,range(len(jvoc))))\n",
    "\n",
    "test_predict(\"solidaritet\",vocabulary_x,iwy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SD (?)\n",
    "Ok. inte klart ännu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
